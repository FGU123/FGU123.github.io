<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis基本数据结构-Sorted Set（SkipList）]]></title>
    <url>%2F2018%2F10%2F26%2FRedis-DataStructure-2-SkipList%2F</url>
    <content type="text"><![CDATA[Sorted Set有序集合键（sorted set）提供的操作非常丰富，可以满足非常多的应用场景。这也意味着，sorted set相对来说实现比较复杂。Redis使用跳跃表（skipList）作为sorted set的底层实现之一，如果一个sorted set包含的元素数量比较多，又或者sorted set中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为sorted set的底层实现。 跳跃表是一种有序数据结构，能支持平均O(logN)、最坏O(N)复杂度的节点查找，在大部分情况下，跳跃表的效率可以和平衡树相媲美，所以不少程序都使用跳跃表来替代平衡树。 sorted set的数据结构有序集合（sorted set）的数据结构底层实现就是跳跃表+字典，如图： 跳跃表的数据结构一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。但skiplist却比较特殊，它没法归属到这两大类里面。 skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。 下面我们从头分析一个要求有序的线性结构的查找元素及插入新元素存在的性能问题。 最容易表达线性结构的自然是数组和链表。可是，无论是数组还是链表，在插入新元素的时候，都会存在性能问题。 如果使用数组，插入新元素的方式如下： 如果要插入一个值是3的元素，首先要知道这个元素应该插入的位置。使用二分查找可以最快定位，这一步时间复杂度是O（logN）。 插入过程中，原数组中所有大于3的元素都要右移，这一步时间复杂度是O（N）。所以总体时间复杂度是O（N）。 如果使用链表，插入新元素的方式如下： 如果要插入一个值是3的元素，首先要知道这个元素应该插入的位置。链表无法使用二分查找，只能和原链表中的节点逐一比较大小来确定位置。这一步的时间复杂度是O（N）。 插入的过程倒是很容易，直接改变节点指针的目标，时间复杂度O（1）。因此总体的时间复杂度也是O（N）。 这对于拥有几十万元素的集合来说，这两种方法显然都太慢了。 问题来了，既然数组也不行，链表也不想，那要用什么结构才好？ 我们可以利用索引的思想，提取出链表中的部分关键节点。 比如给定一个长度是7的有序链表，节点值依次是1→2→3→5→6→7→8。那么我们可以取出所有奇数值的节点作为关键字。 此时如果要插入一个值是4的新节点，不再需要和原节点8,7,6,5,3逐一比较，只需要比较关键节点7,5,3 确定了新节点在关键节点中的位置（3和5之间），就可以回到原链表，迅速定位到对应的位置插入（同样3和5之间） 当链表中有1W设置10W个节点，优化效果会很明显，比较次数就整整减少了一半！但是这样的做法只是增加了50%的额外空间，却换来了一倍的性能提高。 不过我们可以进一步思考，既然已经提取了一层关键节点作为索引，那我们为何不能从索引中进一步提取，再提取一层索引的索引呢？ 于是乎，我们有了2级索引之后，新的节点可以先和2级索引比较，确定大体范围；然后再和1级索引比较；最后再回到原链表，找到并插入对应位置。 当节点很多的时候，比较次数会减少到原来的1/4，如是者，如果我们再继续往上提取更高层的索引，保证每一层是上一层节点的一半，一直到同一层只有两个节点（因为只有一个节点没有比较的意义），那么这样一个多层链表结构，便是我们的跳跃表。 那么，跳跃表的介绍引子至此已告一段落，下面是一个正儿八经的跳跃表的概念的介绍： 我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）： 在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。 假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图： 这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的： 23首先和7比较，再和19比较，比它们都大，继续向后比较。 但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。 23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。 在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图： 在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。 skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。 skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程: 从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。这在后面我们还会提到。 根据上图中的skiplist结构，我们很容易理解这种数据结构的名字的由来。skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。 刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径： 需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。 至此，skiplist的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。 当然，实际应用中的skiplist每个节点应该包含key和value两部分。前面的描述中我们没有具体区分key和value，但实际上列表中是按照key进行排序的，查找过程也是根据key在比较。 但是，如果你是第一次接触skiplist，那么一定会产生一个疑问：节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？为了回答这个疑问，我们需要分析skiplist的统计性能。 在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下： 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。 如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。 节点最大的层数不允许超过一个最大值，记为MaxLevel。 这个计算随机层数的伪码如下所示： 123456randomLevel() level := 1 // random()返回一个[0...1)的随机数 while random() &lt; p and level &lt; MaxLevel do level := level + 1 return level randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为： 12p = 1/4MaxLevel = 32 skiplist与平衡树、哈希表的比较 skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 从算法实现难度上来比较，skiplist比平衡树要简单得多。 Redis中的sorted set我们前面提到过，Redis中的sorted set，是在skiplist, dict和ziplist基础上构建起来的: 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。在本系列前面关于ziplist的文章里，我们介绍过，ziplist就是由很多数据项组成的一大块连续内存。由于sorted set的每一项元素都由数据和score组成，因此，当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。 ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。 随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？ 在redis.conf中的ADVANCED CONFIG部分的两个Redis配置12zset-max-ziplist-entries 128zset-max-ziplist-value 64 这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）： 当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。 当sorted set中插入的任意一个数据的长度超过了64的时候。 最后，zset结构的代码定义如下：1234typedef struct zset &#123; dict *dict; zskiplist *zsl;&#125; zset; Redis为什么用skiplist而不用平衡树？在前面我们对于skiplist和平衡树、哈希表的比较中，其实已经不难看出Redis里使用skiplist而不用平衡树的原因了。现在我们看看，对于这个问题，Redis的作者 @antirez 是怎么说的： There are a few reasons: They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees. A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees. They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code. 这段话原文出处： https://news.ycombinator.com/item?id=1171423这里从内存占用、对范围查找的支持和实现难易程度这三方面总结的原因]]></content>
      <tags>
        <tag>Redis</tag>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
        <tag>SkipList</tag>
        <tag>跳跃表</tag>
        <tag>跳表</tag>
        <tag>sorted-set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死锁]]></title>
    <url>%2F2018%2F10%2F21%2Fdead-lock%2F</url>
    <content type="text"><![CDATA[“死锁”的含义所谓死锁： 是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 Java代码举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Deadlock &#123; private Object o1 = new Object(); private Object o2 = new Object(); public void lock1() &#123; // 获取o1对象锁 synchronized( o1 ) &#123; try &#123; System.out.println( "l1 lock o1" ); // 获取o1后先等一会儿，让Lock2有足够的时间锁住o2 Thread.sleep( 1000 ); // 接着获取o2对象锁 synchronized( o2 ) &#123; System.out.println( "l1 lock o2" ); &#125; &#125; catch( Exception e ) &#123; e.printStackTrace(); &#125; &#125; &#125; public void lock2() &#123; // 获取o2对象锁 synchronized( o2 ) &#123; try &#123; System.out.println( "l2 lock o2" ); // 获取o2后先等一会儿，让Lock1有足够的时间锁住o1 Thread.sleep( 1000 ); // 接着获取o1对象锁 synchronized( o1 ) &#123; System.out.println( "l2 lock o1" ); &#125; &#125; catch( Exception e ) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main( String[] args ) &#123; Deadlock lock = new Deadlock(); Thread t1 = new Thread( new Runnable() &#123; @Override public void run() &#123; lock.lock1(); &#125; &#125; ); Thread t2 = new Thread( new Runnable() &#123; @Override public void run() &#123; lock.lock2(); &#125; &#125; ); t1.start(); t2.start(); &#125;&#125; 创建两个对象，两条线程，用synchronized锁住对象，线程1先锁对象1后锁对象2，线程2先锁对象2后锁对象1。假设线程1先锁对象1，然后休眠1秒，线程锁对象2，之后线程1就没法锁对象2，线程2也没法锁住对象1，双方都在等待对方释放自己在等待的锁。 “死锁”产生的原因及四个必要条件“死锁”的原因可归结为 竞争资源。当系统中供多个进程共享的资源如打印机、公用队列等，其数目不足以满足进程的需要时，会引起诸进程的竞争而产生死锁。 进程间推进顺序非法。进程在运行过程中，请求和释放资源的顺序不当，也同样会导致产生进程死锁。 产生“死锁”的四个必要条件 互斥（Mutual exclusion）：存在这样一种资源，它在某个时刻只能被分配给一个执行绪（也称为线程）使用； 持有（Hold and wait）：当请求的资源已被占用从而导致执行绪阻塞时，资源占用者不但没有释放该资源，而且还可以继续请求更多资源； 不可剥夺（No preemption）：执行绪获得到的互斥资源不可被强行剥夺，换句话说，只有资源占用者自己才能释放资源； 环形等待（Circular wait）：若干执行绪以不同的次序获取互斥资源，从而形成环形等待的局面，想象在由多个执行绪组成的环形链中，每个执行绪都在等待下一个执行绪释放它持有的资源。 结合代码例子理解“死锁”的产生 互斥：两条线程各自占有的锁 持有：线程1持有线程2想要获得的锁1，线程2持有线程1想要的锁2，双方都没有 释放各自占有的对象锁，并且继续请求对方占有的锁 不可剥夺：两条线程得到互斥资源都没法被强行剥夺 环形等待：T1{O1}→→T2{O2}→→T1{O1}，{}表示被左边的线程占有{}里的资源，→→表示左边线程申请（等待）右边线程释放其占有的资源PS：环形等待可以是多个线程对多个资源的争夺 “死锁”问题定位获取java进程ID1ps aux | grep "java" 用jstack看进程堆栈12# 替换进程ID（pid）jstack -l &#123;pid&#125; | grep -A50 -B10 "deadlock" “死锁”的预防和解除理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁，消除产生死锁的四个必要条件中的任何一个都可以预防和解除死锁。不难看出，在死锁的四个必要条件中，第二、三和四项条件比较容易消除。 静态分配：采用资源静态分配策略（进程资源静态分配方式是指一个进程在建立时就分配了它需要的全部资源），破坏”部分分配”条件； 可剥夺：允许进程剥夺使用其他进程占有的资源，从而破坏”不可剥夺”条件； 有序分配：采用资源有序分配法，破坏”环路”条件 参考资料“死锁”四个必要条件的合理解释]]></content>
      <tags>
        <tag>线程</tag>
        <tag>并发</tag>
        <tag>Java</tag>
        <tag>死锁</tag>
        <tag>DeadLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基本数据结构-String]]></title>
    <url>%2F2018%2F10%2F14%2FRedis-DataStructure-1-String%2F</url>
    <content type="text"><![CDATA[String&emsp;&emsp;String是我们最常用的Redis基本数据结构之一。Redis没有直接使用C语言传统的字符串表示（以空字符结尾的字符数组，以下简称C字符串），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将SDS用作Redis的默认字符串表示。&emsp;&emsp;在Redis里边，C字符串只会作为字符串字面量用在一些无须对字符串值进行修改的地方，比如打印日志：1redisLog(REDIS_WARNING, &quot;Redis is now ready to exit, bye bye...&quot;); SDS与C字符串的区别常数级复杂度获取字符串长度&emsp;&emsp;C语言使用长度为N+1的字符串来表示长度为N的字符串，并且字符数组的最后一个元素总是空字符’\0’&emsp;&emsp;因为C字符串并不记录自身的长度信息，所以为了获取一个C字符串的长度，程序必须便利整个字符数组，对遇到的每个字符进行技术，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为O(N)&emsp;&emsp;和C字符串不同，因为SDS在len属性中记录了SDS本身的长度，所以获取一个SDS长度的复杂度仅为O(1)，这确保了获取字符串长度的操作不会成为Redis的性能瓶颈。譬如”Redis”的长度为5，程序只需要访问SDS的len属性就可以立即得到长度值为5字节 杜绝缓冲区溢出&emsp;&emsp;由于C字符串不记录自身长度，会带来另一个问题，就是容易造成缓冲区溢出。1char *strcat(char *dest, const char *src) &emsp;&emsp;假定用户在执行strcat函数时，已经为dest分配了足够多的内存，则可以容纳src字符串中的所有内容，而一旦这个假定不成立时，就会产生缓冲区溢出。&emsp;&emsp;举个例子，假设程序里有两个在内存中紧邻着的C字符串s1和s2，其中s1保存了字符串”Redis”，而s2则保存了字符串”MongoDB”，如图所示： &emsp;&emsp;如果此时要通过执行：1strcat(s1, &quot; Cluster&quot;); 将s1的内容修改为”Redis Cluster”，但如果粗心的他却忘了在执行strcat之前为s1分配足够的空间，那么在strcat函数执行之后，s1的数据将溢出到s2所在的空间中，导致s2的内容被意外地修改了，如图所示： &emsp;&emsp;SDS的空间分配策略则完全杜绝了发生这种情况的可能性：当SDS API需要对SDS的内容进行修改时，API会先检查SDS的空间是否满足修改所需的要求，如果不满足的话，API会自动把SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用SDS既不需要手动修改SDS的空间大小，也不会出现上述的缓冲区溢出问题。 减少修改字符串时带来的内容重分配次数&emsp;&emsp;因为C字符串并不记录自身的长度，所以一个C字符串的底层实现总是额外的多出一个字符空间用于保存空字符。因为C字符串的长度和底层数组长度之间存在着这种关联性，所以每次增长或缩短一个C字符串，都总会在保存这个C字符串的数组时引起一次内存重分配操作 &emsp;&emsp;而因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作： 在一般程序中，如果修改字符串长度的情况不太常出现，那么每次修改都执行一次内存重分配是可以接受的，但Redis作为数据库，经常被用于速度要求严苛、数据被频繁修改的场合，如果每次修改字符串的长度都需要执行一次内存重分配的话，那么光是这个操作的时间就会占去修改字符串所用时间的一大部分，如果这种修改频繁地发生的话，可能还会对性能造成影响 &emsp;&emsp;为了避免C字符串的这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：在SDS中，buf数组的长度不一定就是字符数加1，数组里边可以包含未使用的字节，而这些字节的数量就由SDS的free属性记录&emsp;&emsp;通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略： 空间预分配&emsp;&emsp;空间预分配用于优化SDS的字符串增长操作：利用额外的未使用空间进行预分配以减少内存的频繁分配，这一点类似Java中的ArrayList。&emsp;&emsp;当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。而字符串最大长度为 512M。譬如，假如SDS进行修改后变为13字节（小于1MB），那么此时SDS的buf数组的实际长度将变成13+13+1=27字节（额外的1字节用于保存空字符）。假如SDS进行修改后变为2MB（大于等于1MB），则程序将会分配1MB的未使用空间，也就是说，SDS的buf数组的实际长度将为2MB + 1MB + 1byte。 惰性空间释放&emsp;&emsp;当要缩短SDS保存的字符串时，程序并不立即使用内存充分配来回收缩短后多出来的字节，而是使用表头的free成员将这些字节记录起来以备用。 二进制安全&emsp;&emsp;SDS是二进制安全的，它可以存储任意二进制数据，因为SDS使用len属性的值而不是像C语言字符串那样以空字符（‘\0’）来标识字符串结束。 &emsp;&emsp;因为传统C字符串符合某种编码（比如ASCII），字符串不仅末尾，就连字符串里的内容也不能包含标记着结束的字符。如ASCII这种编码的操作的特点就是：遇零则止。即，当读一个字符串时，只要遇到’\0’结尾，就认为到达末尾，就忽略’\0’结尾以后的所有字符。因此，如果传统字符串保存图片、音频、视频等二进制文件，操作文件时就被截断了。 兼容部分C字符串函数&emsp;&emsp;虽然SDS的API都是二进制安全的，但它们一样遵循C字符串结尾的惯例：这些API总会将SDS保存的数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个空字符，这是为了让那些保存文本数据的SDS可以重用一部分&lt;string.h&gt;库定义的函数，避免不必要的代码重复。 总结]]></content>
      <tags>
        <tag>Redis</tag>
        <tag>Data Structure</tag>
        <tag>String</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo添加搜索功能]]></title>
    <url>%2F2018%2F10%2F14%2FHexo-Search%2F</url>
    <content type="text"><![CDATA[本文旨在记录站主基于hexo-generator-search插件实现本站的站内文章搜索功能 基本实现原理 基于hexo-generator-search生成全文内容索引xml文件 利用jQ.ajax请求xml文件并解析 jQ搜索关键字内容匹配xml内容主要的部分还是插件写的好，对应的解析函数也是改造插件作者的，网上一搜一大堆此类文章，本文仅仅意在记录本站使用该插件实现搜索的过程 安装插件1npm install --save hexo-generator-search 这个插件可以生成供搜索的索引数据，生成后的xml文件保存在自己站内目录，可以通过 http://localhost:4000/search.xml 查看 插件配置在hexo根目录底下的_config.xml里加入以下配置：1234search: path: search.xml field: post #field: post, page or all（3个可选参数） 解析函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960var performLocalSearch = function(datas,keywords)&#123; // perform local searching var str='&lt;ul class="search-result-list"&gt;'; datas.forEach(function(data) &#123; var isMatch = true; var content_index = []; var data_title = data.title.trim().toLowerCase(); var data_content = data.content.trim().replace(/&lt;[^&gt;]+&gt;/g,"").toLowerCase(); var data_url = "/" + data.url; var index_title = -1; var index_content = -1; var first_occur = -1; // only match artiles with not empty titles and contents if(data_title != '' &amp;&amp; data_content != '') &#123; keywords.forEach(function(keyword, i) &#123; index_title = data_title.indexOf(keyword); index_content = data_content.indexOf(keyword); if( index_title &lt; 0 &amp;&amp; index_content &lt; 0 )&#123; isMatch = false; &#125; else &#123; if (index_content &lt; 0) &#123; index_content = 0; &#125; if (i == 0) &#123; first_occur = index_content; &#125; &#125; &#125;); &#125; // show search results if (isMatch) &#123; str += '&lt;li&gt;&lt;a href="'+ data_url +'" class="search-result-title" target="_blank"&gt;'+ '&gt; ' + data_title +'&lt;/a&gt;'; var content = data.content.trim().replace(/&lt;[^&gt;]+&gt;/g,""); if (first_occur &gt;= 0) &#123; // cut out characters var start = first_occur - 6; var end = first_occur + 6; if(start &lt; 0)&#123; start = 0; &#125; if(start == 0)&#123; end = 10; &#125; if(end &gt; content.length)&#123; end = content.length; &#125; var match_content = content.substr(start, end); // highlight all keywords keywords.forEach(function(keyword)&#123; var regS = new RegExp(keyword, "gi"); match_content = match_content.replace(regS, '&lt;em class=\"search-keyword\"&gt;'+keyword+'&lt;/em&gt;'); &#125;); str += '&lt;p class=\"search-result\"&gt;' + match_content +'...&lt;/p&gt;'; &#125; &#125; &#125;); return str; &#125; Search入口功能函数12345678910111213141516171819202122232425262728293031 var searchFunc = function(path, search_id, content_id) &#123; 'use strict'; $.ajax(&#123; url: path, dataType: "xml", success: function( xmlResponse ) &#123; // get the contents from search data var datas = $( "entry", xmlResponse ).map(function() &#123; return &#123; title: $( "title", this ).text(), content: $("content",this).text(), url: $( "url" , this).text() &#125;; &#125;).get(); var $input = $('#'+search_id); var $resultContent = $('#'+content_id); $input.on("input propertychange",function()&#123; var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/); if($(this).val()=="")&#123;$resultContent.html('');return;&#125; $resultContent.html(performLocalSearch(datas,keywords)); &#125;); &#125; &#125;); &#125; searchFunc("/search.xml","local-search-input","local-search-result");&#125;)(); 页面HTML代码申明html元素，id、class名字要跟解析函、Search入口功能函数里的代码对上号：12345 &lt;div id="site_search" class="bar"&gt; &lt;input type="text" id="local-search-input" name="q" results="0" placeholder="search my blog..." class="form-control"/&gt; &lt;div id="local-search-result"&gt;&lt;/div&gt; &lt;/div&gt;` 样式调整1234567891011121314151617181920212223242526272829303132ul.search-result-list &#123; padding-left: 10px;&#125;a.search-result-title &#123; font-weight: bold;&#125;p.search-result &#123; color=#555;&#125;em.search-keyword &#123; border-bottom: 1px dashed #4088b8; font-weight: bold;&#125;.form-control &#123; padding-left:10px; margin-bottom: 10px; &#125;.bar &#123; padding: 10px 10px;&#125;.bar input &#123; width:350px; height: 25px; border-radius:42px; border:2px solid #324B4E; background:#F9F0DA; transition:.3s linear; float:center;&#125;.bar input:focus &#123; width:420px;&#125;]]></content>
      <tags>
        <tag>HEXO</tag>
        <tag>搜索</tag>
        <tag>HEXO-GENERATOR-SEARCH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池类比公司经营之道]]></title>
    <url>%2F2018%2F10%2F03%2FJava-ThreadPool-vs-Company%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;Java线程池的设计与公司经营的相似之处如果我们查看JDK源码，会发现FixedThreadPool、CachedThreadPool和SingleThreadExecutor都是通过创建一个ThreadPoolExcutor对象来实现的。我们来看一下该ThreadPoolExcutor的构造方法，并对线程池中线程的保留和新建策略做进一步的分析。 1public ThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &emsp;&emsp;第一个参数corePoolSize代表了线程池中一定要保持的线程的数量；线程池中的线程可能发生变化，第二个参数maximumPoolSize约束了线程池中所能达到的线程的最大数量；线程有可能一直处于空闲状态，keepAliveTime代表了空闲状态的线程所能存活的时间；TimeUnit代表了时间单位；workQueue是一个缓冲队列，如果任务到达，但是还没有空闲线程可以执行该任务，那么就将该任务置于这个缓冲队列中。为了更加容易理解和记忆线程池这个几个属性的协调工作。我们利用一个精明的老板来比喻线程池。而将线程比作线程中的线程。 &emsp;&emsp;一个公司必须要保留一定数量的核心员工，不管这些员工是不是老闲着。当然，对于非常抠门的老板，这个数量可能是0，例如CachedThreadPool。核心员工的数量，就是corePoolSize。当一个公司初创时，所有的员工也就是那几个核心员工。当线程池新建时，同样只会创建与corePoolSize数量相当的线程。 &emsp;&emsp;当新的任务到达时，如果有空闲线程，马上将这些任务分配给空闲线程。如果没有的话，那么，怎么办呢？新建一个线程吗？非也，对于一个精明的老板来说，他只会把这些任务排进任务列表。手下的员工忙完手头的工作，马上就从任务列表的开头位置移出工作，并分配给空闲。这就让每名员工都不停的工作，甚至加班加点。这个任务列表就是workQueue。 &emsp;&emsp;如果更多的任务涌过来，如同这个公司的业务很好，工作多越堆越多。这个时候，就看任务列表能承受的极限了。有的老板在创立公司的时候，就抱着这种心态——任务列表可以无限长，反正我就招这么多人，客户能等就等，不能等就拉倒。但是，对于很多客户来说，如果等的时间过长，可能就放弃了。具有无限长workQueue的线程池来说，可能同样会导致某些线程等待时间过长，用户任务无响应的问题。 &emsp;&emsp;但是，如果workQueue不是无限长，那么，其容量总有可能被达到。而新的任务到达时，无法存入workQueue。这如同，这个老板既负责任（不想出现客户无限等待的情况），同时又不想放弃任何一个客户。那么，唯有增加员工数量了，这就如同线程池新建线程。但是，公司总要有个风险评估，不能让员工数量无限增长，于是，maximumPoolSize就代表了员工的最大数量。如同说，在无法两全其美的情形下，即使损失部分客户，也要控制公司的成本风险。线程池同样如此，每个线程都将消耗系统资源，这种消耗必须被控制在一定范围之内。 &emsp;&emsp;在大量任务涌入，workQueue无法缓存这些任务，而maxinumPoolSize也已经达到时，相当于一个公司达到了它的最大营运能力，就只能拒绝介绍客户任务了。线程池拒绝介绍新的任务，会抛出异常RejectedExecutionException。 &emsp;&emsp;当然，一个公司的营运既有旺季，也有淡季。上面我们所描述的情形是旺季的营运。如果淡季到了，许多员工都闲下来了。老板就会考虑裁员了。当然，老板不会马上动手，因为不能准确把握旺季和淡季的分界线。他会给空闲员工一个缓冲期，如果这个员工闲了三个月都没工作，那么证明，真的需要裁掉他了。对应到线程池中，keepAliveTime和TimeUnit限制了一个线程的最大空闲时间。相当于一个缓冲期，缓冲期一结束，就会将其销毁，以释放系统资源。当然，这些被“处理”的线程都是核心员工数量之外的，线程池总会保留corePoolSize个线程备用。 &emsp;&emsp;通过以上描述，我们应该对线程池的运作策略有了一个比较清晰的认识。总结这种策略，主要目的是基于成本考虑——尽量耗用最少的内存，来完成尽可能多的任务。]]></content>
      <tags>
        <tag>线程池</tag>
        <tag>线程</tag>
        <tag>ThreadPool</tag>
        <tag>corePoolSize</tag>
        <tag>workQueue</tag>
        <tag>并发</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Hello World]]></title>
    <url>%2F2018%2F10%2F03%2FHexo-First-Guide%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>HEXO</tag>
      </tags>
  </entry>
</search>
